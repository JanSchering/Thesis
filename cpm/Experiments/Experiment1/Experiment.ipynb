{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from hamiltonian_diff import model\n",
    "from cell_typing import CellKind, CellMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 1., 1., 1., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "grid = t.zeros((1,5,5))\n",
    "grid[0,1,2] = 1\n",
    "grid[0,2,1] = 1\n",
    "grid[0,2,2] = 1\n",
    "grid[0,2,3] = 1\n",
    "grid[0,3,2] = 1\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_perim1 = t.tensor(10.)\n",
    "lambda_perim1 = t.tensor(1.)\n",
    "target_vol1 = t.tensor(7.)\n",
    "lambda_vol1 = t.tensor(1.)\n",
    "adh_cost1 = {0: t.tensor(2.)}\n",
    "cell1 = CellKind(\n",
    "    type_id=1,\n",
    "    target_perimeter=target_perim1,\n",
    "    lambda_perimeter=lambda_perim1,\n",
    "    target_volume=target_vol1,\n",
    "    lambda_volume=lambda_vol1,\n",
    "    adhesion_cost=adh_cost1\n",
    ")\n",
    "cell_map = CellMap()\n",
    "cell_map.add(cell_id=1, cell_type=cell1)\n",
    "\n",
    "temperature = t.tensor(27.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid, stats = model(grid, cell_map, temperature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 3 2]]\n",
      "[[0 4 3]]\n",
      "{'volume_energy': tensor([4.]), 'perimeter_energy': tensor([196.]), 'adh_e': tensor([48.]), 'h': tensor([248.])}\n",
      "{'volume_energy': tensor([1.]), 'perimeter_energy': tensor([400.]), 'adh_e': tensor([60.]), 'h': tensor([461.])}\n",
      "tensor([213.])\n",
      "tensor([0.0004])\n",
      "tensor(1.)\n",
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 1., 1., 1., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "print(stats[\"src_pixel\"])\n",
    "print(stats[\"target_pixel\"])\n",
    "print(stats[\"current\"])\n",
    "print(stats[\"adjusted\"])\n",
    "print(stats[\"h_diff\"])\n",
    "print(stats[\"p_copy\"])\n",
    "print(stats[\"success\"])\n",
    "print(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hamiltonian_diff import hamiltonian_energy\n",
    "\n",
    "target_vol1.requires_grad_()\n",
    "e, stats = hamiltonian_energy(grid, cell_map, use_volume=True, use_perimeter=True, use_adhesion=True)\n",
    "grad = t.autograd.grad(e, target_vol1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(2.),)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 1., 1., 1., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "[array(-10., dtype=float32), array(-8., dtype=float32), array(-6., dtype=float32), array(-4., dtype=float32), array(-2., dtype=float32), array(0., dtype=float32), array(2., dtype=float32), array(4., dtype=float32), array(6., dtype=float32), array(8., dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(grid)\n",
    "vols = t.linspace(1, 10, 10)\n",
    "\n",
    "grads = []\n",
    "for vol in vols:\n",
    "    vol.requires_grad_()\n",
    "    cell1 = CellKind(\n",
    "        type_id=1,\n",
    "        target_perimeter=target_perim1,\n",
    "        lambda_perimeter=lambda_perim1,\n",
    "        target_volume=vol,\n",
    "        lambda_volume=lambda_vol1,\n",
    "        adhesion_cost=adh_cost1\n",
    "    )\n",
    "    cell_map = CellMap()\n",
    "    cell_map.add(cell_id=1, cell_type=cell1)\n",
    "    e, stats = hamiltonian_energy(grid, cell_map, use_volume=True, use_perimeter=True, use_adhesion=True)\n",
    "    grad = t.autograd.grad(e, vol)[0]\n",
    "    grads.append(grad.detach().numpy())\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x18974dffc10>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(vols, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0: -10.0\n",
      "2.0: -8.0\n",
      "3.0: -6.0\n",
      "4.0: -4.0\n",
      "5.0: -2.0\n",
      "6.0: 0.0\n",
      "7.0: 2.0\n",
      "8.0: 4.0\n",
      "9.0: 6.0\n",
      "10.0: 8.0\n"
     ]
    }
   ],
   "source": [
    "for idx, vol in enumerate(vols):\n",
    "    print(f\"{vol}: {grads[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 1., 1., 1., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "[array(-58., dtype=float32), array(-56., dtype=float32), array(-54., dtype=float32), array(-52., dtype=float32), array(-50., dtype=float32), array(-48., dtype=float32), array(-46., dtype=float32), array(-44., dtype=float32), array(-42., dtype=float32), array(-40., dtype=float32), array(-38., dtype=float32), array(-36., dtype=float32), array(-34., dtype=float32), array(-32., dtype=float32), array(-30., dtype=float32), array(-28., dtype=float32), array(-26., dtype=float32), array(-24., dtype=float32), array(-22., dtype=float32), array(-20., dtype=float32), array(-18., dtype=float32), array(-16., dtype=float32), array(-14., dtype=float32), array(-12., dtype=float32), array(-10., dtype=float32), array(-8., dtype=float32), array(-6., dtype=float32), array(-4., dtype=float32), array(-2., dtype=float32), array(0., dtype=float32), array(2., dtype=float32), array(4., dtype=float32), array(6., dtype=float32), array(8., dtype=float32), array(10., dtype=float32), array(12., dtype=float32), array(14., dtype=float32), array(16., dtype=float32), array(18., dtype=float32), array(20., dtype=float32), array(22., dtype=float32), array(24., dtype=float32), array(26., dtype=float32), array(28., dtype=float32), array(30., dtype=float32), array(32., dtype=float32), array(34., dtype=float32), array(36., dtype=float32), array(38., dtype=float32), array(40., dtype=float32), array(42., dtype=float32), array(44., dtype=float32), array(46., dtype=float32), array(48., dtype=float32), array(50., dtype=float32), array(52., dtype=float32), array(54., dtype=float32), array(56., dtype=float32), array(58., dtype=float32), array(60., dtype=float32), array(62., dtype=float32), array(64., dtype=float32), array(66., dtype=float32), array(68., dtype=float32), array(70., dtype=float32), array(72., dtype=float32), array(74., dtype=float32), array(76., dtype=float32), array(78., dtype=float32), array(80., dtype=float32), array(82., dtype=float32), array(84., dtype=float32), array(86., dtype=float32), array(88., dtype=float32), array(90., dtype=float32), array(92., dtype=float32), array(94., dtype=float32), array(96., dtype=float32), array(98., dtype=float32), array(100., dtype=float32), array(102., dtype=float32), array(104., dtype=float32), array(106., dtype=float32), array(108., dtype=float32), array(110., dtype=float32), array(112., dtype=float32), array(114., dtype=float32), array(116., dtype=float32), array(118., dtype=float32), array(120., dtype=float32), array(122., dtype=float32), array(124., dtype=float32), array(126., dtype=float32), array(128., dtype=float32), array(130., dtype=float32), array(132., dtype=float32), array(134., dtype=float32), array(136., dtype=float32), array(138., dtype=float32), array(140., dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(grid)\n",
    "perims = t.linspace(1, 100, 100)\n",
    "\n",
    "grads = []\n",
    "for perim in perims:\n",
    "    perim.requires_grad_()\n",
    "    cell1 = CellKind(\n",
    "        type_id=1,\n",
    "        target_perimeter=perim,\n",
    "        lambda_perimeter=lambda_perim1,\n",
    "        target_volume=target_vol1,\n",
    "        lambda_volume=lambda_vol1,\n",
    "        adhesion_cost=adh_cost1\n",
    "    )\n",
    "    cell_map = CellMap()\n",
    "    cell_map.add(cell_id=1, cell_type=cell1)\n",
    "    e, stats = hamiltonian_energy(grid, cell_map, use_volume=True, use_perimeter=True, use_adhesion=True)\n",
    "    grad = t.autograd.grad(e, perim)[0]\n",
    "    grads.append(grad.detach().numpy())\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1897b02e230>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(perims, grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 1., 1., 1., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 1., 0.]]])\n",
      "[array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32), array(30., dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "print(grid)\n",
    "adhesions = t.linspace(1, 100, 100)\n",
    "\n",
    "e_vals = []\n",
    "grads = []\n",
    "for adh in adhesions:\n",
    "    adh.requires_grad_()\n",
    "    adh_cost = {\n",
    "        0: adh\n",
    "    }\n",
    "    cell1 = CellKind(\n",
    "        type_id=1,\n",
    "        target_perimeter=target_perim1,\n",
    "        lambda_perimeter=lambda_perim1,\n",
    "        target_volume=target_vol1,\n",
    "        lambda_volume=lambda_vol1,\n",
    "        adhesion_cost=adh_cost\n",
    "    )\n",
    "    cell_map = CellMap()\n",
    "    cell_map.add(cell_id=1, cell_type=cell1)\n",
    "    e, stats = hamiltonian_energy(grid, cell_map, use_volume=True, use_perimeter=True, use_adhesion=True)\n",
    "    grad = t.autograd.grad(e, adh)[0]\n",
    "    grads.append(grad.detach().numpy())\n",
    "    e_vals.append(e.detach().numpy())\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1897b0b9ab0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(adhesions, grads)\n",
    "plt.plot(adhesions, e_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0.]]]),)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adh_cost1 = {0: t.tensor(2.)}\n",
    "cell1 = CellKind(\n",
    "    type_id=1,\n",
    "    target_perimeter=target_perim1,\n",
    "    lambda_perimeter=lambda_perim1,\n",
    "    target_volume=target_vol1,\n",
    "    lambda_volume=lambda_vol1,\n",
    "    adhesion_cost=adh_cost1\n",
    ")\n",
    "cell_map = CellMap()\n",
    "cell_map.add(cell_id=1, cell_type=cell1)\n",
    "grid.requires_grad_()\n",
    "e, stats = hamiltonian_energy(grid, cell_map, use_volume=True, use_perimeter=True, use_adhesion=True)\n",
    "t.autograd.grad(e, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-2., -2., -2., -2., -2.],\n",
       "          [-2., -2., -2., -2., -2.],\n",
       "          [-2., -2., -2., -2., -2.],\n",
       "          [-2., -2., -2., -2., -2.],\n",
       "          [-2., -2., -2., -2., -2.]]]),)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.requires_grad_()\n",
    "loss = t.sum((grid - (grid.detach() + 1)) ** 2)\n",
    "t.autograd.grad(loss, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from volume_diff import volume_energy\n",
    "\n",
    "volume_energy(grid, cell_map)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from volume_diff import id_batched_volume\n",
    "\n",
    "grid.requires_grad_()\n",
    "\n",
    "loss_fn = t.nn.BCELoss()\n",
    "loss = loss_fn(t.ones(grid.shape), grid)\n",
    "test_loss = (loss - t.tensor(10.)) ** 2\n",
    "\n",
    "grad = t.autograd.grad(test_loss, grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[-inf, -inf, -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf, -inf, -inf],\n",
      "         [-inf, -inf, -inf, -inf, -inf]]]),)\n"
     ]
    }
   ],
   "source": [
    "print(grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.),)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.tensor(2.)\n",
    "a.requires_grad_()\n",
    "loss = 0 ** ((a - t.tensor(4.)) ** 2)\n",
    "t.autograd.grad(loss, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0., grad_fn=<PowBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class STETest(t.autograd.Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, input):\n",
    "        return (input == 0).float()\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        return grad_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.),)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = STETest.apply(a - t.tensor(4.))\n",
    "t.autograd.grad(loss, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1897d180e20>]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grads = []\n",
    "losses = []\n",
    "for i in range(10):\n",
    "    a = t.tensor(float(i), requires_grad=True)\n",
    "    loss = STETest.apply((a - t.tensor(4.))**2)\n",
    "    grad = t.autograd.grad(loss, a)[0]\n",
    "    grads.append(grad.detach().numpy())\n",
    "    losses.append(loss.detach().numpy())\n",
    "plt.plot(range(10), grads)\n",
    "plt.plot(range(10), losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_state = t.load(\"input_pic.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1894e27a260>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(input_state[0].cpu(),cmap=\"Greys\",interpolation=\"nearest\",vmin=0,vmax=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 25\n",
    "\n",
    "grid = input_state[0].detach().clone()\n",
    "grid[grid < 25] = 0\n",
    "grid[grid >= 25] = 1\n",
    "grid = grid.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 64, 64])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1894e2ee950>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(grid[0].cpu(),cmap=\"Greys\",interpolation=\"nearest\",vmin=0,vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"../../\")\n",
    "from periodic_padding import periodic_padding\n",
    "\n",
    "unfold_transform = t.nn.Unfold(kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bg_contacts(conv_mat:t.Tensor) -> t.Tensor:\n",
    "    num_convs = conv_mat.shape[1]\n",
    "    return t.sum((1 - conv_mat) * conv_mat[:,:,4].T.expand(num_convs, 9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 1., 1., 1., 0.],\n",
       "         [0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0.]]], requires_grad=True)"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = t.zeros((1, 5, 5))\n",
    "batch[0, 2, 1] = 1\n",
    "batch[0, 2, 2] = 1\n",
    "batch[0, 2, 3] = 1\n",
    "batch[0, 1, 2] = 1\n",
    "batch[0, 3, 2] = 1\n",
    "batch.requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(batch):\n",
    "    # provide a periodic torus padding to the grid\n",
    "    padded_batch = periodic_padding(batch)\n",
    "    # we need to add a channel dimension because unfold expects vectors of shape (N,C,H,W)\n",
    "    padded_batch = padded_batch.unsqueeze(1)\n",
    "    # apply the unfolding operator on the padded grid, this provides all convolution blocks\n",
    "    unfolded_batch = unfold_transform(padded_batch)\n",
    "    # turn each convolution block into a row\n",
    "    batch_reshaped = unfolded_batch.permute(0, 2, 1)\n",
    "    print(bg_contacts(batch_reshaped))\n",
    "    print(t.sum(batch))\n",
    "    return bg_contacts(batch_reshaped) + (t.sum(batch) - t.tensor(4.))**2 * 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24., grad_fn=<SumBackward0>)\n",
      "tensor(5., grad_fn=<SumBackward0>)\n",
      "loss: 29.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[19., 17., 17., 17., 19.],\n",
       "          [17., 13., 11., 13., 17.],\n",
       "          [17., 11.,  9., 11., 17.],\n",
       "          [17., 13., 11., 13., 17.],\n",
       "          [19., 17., 17., 17., 19.]]]),)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = calc_loss(batch)\n",
    "print(f\"loss: {loss}\" )\n",
    "t.autograd.grad(loss, batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(24., grad_fn=<SumBackward0>)\n",
      "tensor(4., grad_fn=<SumBackward0>)\n",
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 1., 0., 1., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], requires_grad=True)\n",
      "loss: 24.0\n",
      "tensor([[[9., 7., 7., 7., 9.],\n",
      "         [7., 5., 3., 5., 7.],\n",
      "         [7., 3., 1., 3., 7.],\n",
      "         [7., 5., 3., 5., 7.],\n",
      "         [9., 7., 7., 7., 9.]]])\n"
     ]
    }
   ],
   "source": [
    "new_batch = batch.detach().clone()\n",
    "new_batch[0,2,2] = 0\n",
    "new_batch.requires_grad_()\n",
    "loss = calc_loss(new_batch)\n",
    "print(new_batch)\n",
    "print(f\"loss: {loss}\" )\n",
    "grads = t.autograd.grad(loss, new_batch)[0]\n",
    "print(grads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n",
      "tensor(21.4498, grad_fn=<SumBackward0>)\n",
      "tensor(3.7059, grad_fn=<SumBackward0>)\n",
      "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
      "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)\n",
      "loss: 21.882352828979492\n"
     ]
    }
   ],
   "source": [
    "for i in range(1000):\n",
    "    loss = calc_loss(new_batch)\n",
    "    print(new_batch)\n",
    "    print(f\"loss: {loss}\" )\n",
    "    grads = t.autograd.grad(loss, new_batch)[0]\n",
    "    new_batch = t.clamp(new_batch - 0.01 * grads, min=0, max=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
       "         [0.0000, 0.6765, 1.0000, 0.6765, 0.0000],\n",
       "         [0.0000, 0.0000, 0.6765, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000]]], grad_fn=<ClampBackward1>)"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.3235, 0.6765],\n",
      "        [0.3235, 0.6765],\n",
      "        [0.3235, 0.6765],\n",
      "        [0.3235, 0.6765]], grad_fn=<CatBackward0>)\n",
      "tensor([[1., 0.],\n",
      "        [0., 1.],\n",
      "        [1., 0.],\n",
      "        [0., 1.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "mask = t.logical_and(new_batch != 0, new_batch != 1)\n",
    "p_vec = new_batch[mask].unsqueeze(1)\n",
    "p_vec_expanded = t.cat((1-p_vec, p_vec), dim=1)\n",
    "print(p_vec_expanded)\n",
    "gumbel_samples = t.nn.functional.gumbel_softmax(t.special.logit(p_vec_expanded), tau=1.0, hard=True)\n",
    "print(gumbel_samples)\n",
    "cell_ids = 1 - gumbel_samples[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0., 0., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.],\n",
      "         [0., 1., 1., 0., 0.],\n",
      "         [0., 0., 1., 0., 0.],\n",
      "         [0., 0., 0., 0., 0.]]], grad_fn=<IndexPutBackward0>)\n",
      "tensor(2., grad_fn=<SumBackward0>)\n"
     ]
    }
   ],
   "source": [
    "reconstruction = t.zeros(*new_batch.shape)\n",
    "reconstruction.shape\n",
    "reconstruction[t.logical_not(mask)] += new_batch[t.logical_not(mask)]\n",
    "reconstruction[mask] += cell_ids\n",
    "print(reconstruction)\n",
    "loss = t.sum((batch - reconstruction)**2)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000, -2.6764,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000, -4.5226,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]]])"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.autograd.grad(loss, new_batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f6d311bf2deaa808a0885101ee1a3c95bac385a15895212a243ca1ac1602dab1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
