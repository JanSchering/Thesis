{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Random walk CPM \n",
    "The goal of this experiment is to apply gradient-based learning to a simplified CPM model simulating a random walk "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "from periodic_padding import periodic_padding\n",
    "from hamiltonian_diff import model\n",
    "from cell_typing import CellKind, CellMap"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Splitting the grid into subdomains for parallel checkerboarding update scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_grids(batch:t.Tensor, kernel_width: int, kernel_height: int) -> t.Tensor:\n",
    "    unfold_transform = t.nn.Unfold(kernel_size=(kernel_height,kernel_width))\n",
    "    \n",
    "    padded_batch = periodic_padding(batch).float()\n",
    "    padded_batch = padded_batch.unsqueeze(1)\n",
    "    \n",
    "    return t.transpose(unfold_transform(padded_batch), dim0=1, dim1=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to split the grid into smaller subdomains of a given size. E.g. we may want to create subgrids of size 2x2. To update these subdomains, we also need the Moore Neighborhood around them. \n",
    "\n",
    "To achieve that, we can apply periodic padding and then use an Unfolding convolution layer. Using a kernel size of $k=(4,4)$ (subdomain dims + 2) we get convolutional blocks containing the desired 2x2 subgrids + Moore neighborhood, unrolled into vectors (one vector for each convolutional block)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]],\n",
      "\n",
      "        [[16, 17, 18, 19],\n",
      "         [20, 21, 22, 23],\n",
      "         [24, 25, 26, 27],\n",
      "         [28, 29, 30, 31]]])\n",
      "torch.Size([2, 9, 16])\n"
     ]
    }
   ],
   "source": [
    "test = t.arange(2*4*4).reshape(2,4,4)\n",
    "print(test)\n",
    "\n",
    "split = split_grids(test, kernel_width=4, kernel_height=4)\n",
    "print(split.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can also use different kernel sizes for the width and height. E.g. we may want to only consider 1x2 subgrids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11],\n",
      "         [12, 13, 14, 15]],\n",
      "\n",
      "        [[16, 17, 18, 19],\n",
      "         [20, 21, 22, 23],\n",
      "         [24, 25, 26, 27],\n",
      "         [28, 29, 30, 31]]])\n",
      "torch.Size([2, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "test = t.arange(2*4*4).reshape(2,4,4)\n",
    "print(test)\n",
    "\n",
    "split = split_grids(test, kernel_width=4, kernel_height=3)\n",
    "print(split.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To apply checkerboarding, we want to choose a set of subgrids where there is at least 2 columns/rows between them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.],\n",
      "         [ 8.,  9., 10., 11., 12., 13., 14., 15.],\n",
      "         [16., 17., 18., 19., 20., 21., 22., 23.],\n",
      "         [24., 25., 26., 27., 28., 29., 30., 31.],\n",
      "         [32., 33., 34., 35., 36., 37., 38., 39.],\n",
      "         [40., 41., 42., 43., 44., 45., 46., 47.],\n",
      "         [48., 49., 50., 51., 52., 53., 54., 55.],\n",
      "         [56., 57., 58., 59., 60., 61., 62., 63.]]])\n"
     ]
    }
   ],
   "source": [
    "test = t.arange(64.).reshape(1,8,8)\n",
    "print(test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On this 8x8 grid, we want to consider a split into 16 2x2 subdomains:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split shape: torch.Size([1, 49, 16])\n",
      "tensor([[63., 56., 57., 58.],\n",
      "        [ 7.,  0.,  1.,  2.],\n",
      "        [15.,  8.,  9., 10.],\n",
      "        [23., 16., 17., 18.]])\n"
     ]
    }
   ],
   "source": [
    "split = split_grids(test, kernel_width=4, kernel_height=4)\n",
    "print(f\"split shape: {split.shape}\")\n",
    "# we can visualize the first convolutional block we receive this way\n",
    "print(split[0,0].reshape(4,4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell above, we see that when we reshape the vector into a 2D block, we indeed get the top-left 2x2 subgrid with its Moore neighborhood.\n",
    "\n",
    "The 3rd convolutional block on the other hand corresponds to the next subgrid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[57., 58., 59., 60.],\n",
      "        [ 1.,  2.,  3.,  4.],\n",
      "        [ 9., 10., 11., 12.],\n",
      "        [17., 18., 19., 20.]])\n"
     ]
    }
   ],
   "source": [
    "print(split[0,2].reshape(4,4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create 4 mutually exclusive sets of subgrids that have at least a spacing of two columns/rows between each other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[63., 56., 57., 58.],\n",
      "         [ 7.,  0.,  1.,  2.],\n",
      "         [15.,  8.,  9., 10.],\n",
      "         [23., 16., 17., 18.]],\n",
      "\n",
      "        [[59., 60., 61., 62.],\n",
      "         [ 3.,  4.,  5.,  6.],\n",
      "         [11., 12., 13., 14.],\n",
      "         [19., 20., 21., 22.]],\n",
      "\n",
      "        [[31., 24., 25., 26.],\n",
      "         [39., 32., 33., 34.],\n",
      "         [47., 40., 41., 42.],\n",
      "         [55., 48., 49., 50.]],\n",
      "\n",
      "        [[27., 28., 29., 30.],\n",
      "         [35., 36., 37., 38.],\n",
      "         [43., 44., 45., 46.],\n",
      "         [51., 52., 53., 54.]]])\n"
     ]
    }
   ],
   "source": [
    "subset1 = split[0, [0, 4, 28, 32]]\n",
    "print(subset1.reshape(4,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[57., 58., 59., 60.],\n",
      "         [ 1.,  2.,  3.,  4.],\n",
      "         [ 9., 10., 11., 12.],\n",
      "         [17., 18., 19., 20.]],\n",
      "\n",
      "        [[61., 62., 63., 56.],\n",
      "         [ 5.,  6.,  7.,  0.],\n",
      "         [13., 14., 15.,  8.],\n",
      "         [21., 22., 23., 16.]],\n",
      "\n",
      "        [[25., 26., 27., 28.],\n",
      "         [33., 34., 35., 36.],\n",
      "         [41., 42., 43., 44.],\n",
      "         [49., 50., 51., 52.]],\n",
      "\n",
      "        [[29., 30., 31., 24.],\n",
      "         [37., 38., 39., 32.],\n",
      "         [45., 46., 47., 40.],\n",
      "         [53., 54., 55., 48.]]])\n"
     ]
    }
   ],
   "source": [
    "subset2 = split[0, [2, 6, 30, 34]]\n",
    "print(subset2.reshape(4,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9., 10., 11., 12.],\n",
      "         [17., 18., 19., 20.],\n",
      "         [25., 26., 27., 28.],\n",
      "         [33., 34., 35., 36.]],\n",
      "\n",
      "        [[13., 14., 15.,  8.],\n",
      "         [21., 22., 23., 16.],\n",
      "         [29., 30., 31., 24.],\n",
      "         [37., 38., 39., 32.]],\n",
      "\n",
      "        [[41., 42., 43., 44.],\n",
      "         [49., 50., 51., 52.],\n",
      "         [57., 58., 59., 60.],\n",
      "         [ 1.,  2.,  3.,  4.]],\n",
      "\n",
      "        [[45., 46., 47., 40.],\n",
      "         [53., 54., 55., 48.],\n",
      "         [61., 62., 63., 56.],\n",
      "         [ 5.,  6.,  7.,  0.]]])\n"
     ]
    }
   ],
   "source": [
    "subset3 = split[0, [16, 20, 44, 48]]\n",
    "print(subset3.reshape(4,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[15.,  8.,  9., 10.],\n",
      "         [23., 16., 17., 18.],\n",
      "         [31., 24., 25., 26.],\n",
      "         [39., 32., 33., 34.]],\n",
      "\n",
      "        [[11., 12., 13., 14.],\n",
      "         [19., 20., 21., 22.],\n",
      "         [27., 28., 29., 30.],\n",
      "         [35., 36., 37., 38.]],\n",
      "\n",
      "        [[47., 40., 41., 42.],\n",
      "         [55., 48., 49., 50.],\n",
      "         [63., 56., 57., 58.],\n",
      "         [ 7.,  0.,  1.,  2.]],\n",
      "\n",
      "        [[43., 44., 45., 46.],\n",
      "         [51., 52., 53., 54.],\n",
      "         [59., 60., 61., 62.],\n",
      "         [ 3.,  4.,  5.,  6.]]])\n"
     ]
    }
   ],
   "source": [
    "subset4 = split[0, [14, 18, 42, 46]]\n",
    "print(subset4.reshape(4,4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4, 4, 4])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_subsets = t.cat((\n",
    "    subset1.reshape(4,4,4).unsqueeze(0),\n",
    "    subset2.reshape(4,4,4).unsqueeze(0),\n",
    "    subset3.reshape(4,4,4).unsqueeze(0),\n",
    "    subset4.reshape(4,4,4).unsqueeze(0)\n",
    "))\n",
    "grid_subsets.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple update probability function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_update(subdomains, cur_vol, target_vol, temperature, src_coords, tgt_coords):\n",
    "    batch_size, _, _ = subdomains.shape \n",
    "    src_x, src_y = src_coords\n",
    "    tgt_x, tgt_y = tgt_coords\n",
    "    vol_changes = (-1 * subdomains[range(batch_size), tgt_y, tgt_x]) + subdomains[range(batch_size), src_y, src_x]\n",
    "    total_vol_change = t.sum(vol_changes)\n",
    "    #print(f\"vol change: {total_vol_change}\")\n",
    "    adjusted_vol = cur_vol + total_vol_change\n",
    "    p_update = t.tensor(0.)\n",
    "    if adjusted_vol <= 2 and adjusted_vol > 0:\n",
    "        p_update += t.exp(-(target_vol - adjusted_vol)**2/temperature)\n",
    "    return p_update"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversion function for subdomain coords to batch coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid_coords(grid_dim, tile_dim, tile_row, tile_col, tile_coords):\n",
    "    tile_y, tile_x = tile_coords\n",
    "    tile_height, tile_width = tile_dim\n",
    "    grid_height, grid_width = grid_dim\n",
    "    \n",
    "    grid_x = tile_col*tile_width+(tile_x-1)\n",
    "    grid_y = tile_row*tile_height+(tile_y-1)\n",
    "    \n",
    "    grid_x[grid_x == -1] = grid_width-1\n",
    "    grid_x[grid_x == grid_width] = 0\n",
    "    \n",
    "    grid_y[grid_y == -1] = grid_height-1\n",
    "    grid_y[grid_y == grid_height] = 0\n",
    "    \n",
    "    return t.vstack((grid_y, grid_x)).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_grid = t.arange(64.).reshape(8,8)\n",
    "grid_dim = (8,8)\n",
    "tile_dim = (2,2)\n",
    "\n",
    "\n",
    "tile_row = t.tensor(0)\n",
    "tile_col = t.tensor(0)\n",
    "tile_coords = (t.tensor(1),t.tensor(1)) \n",
    "coords = get_grid_coords(grid_dim, tile_dim, tile_row, tile_col, tile_coords)\n",
    "assert t.all(coords == t.tensor([(0,0)]))\n",
    "assert test_grid[coords[:,0], coords[:,1]] == 0\n",
    "\n",
    "tile_row = t.tensor(0)\n",
    "tile_col = t.tensor(0)\n",
    "tile_coords = (t.tensor(0),t.tensor(0)) \n",
    "coords = get_grid_coords(grid_dim, tile_dim, tile_row, tile_col, tile_coords)\n",
    "assert t.all(coords == t.tensor([(7,7)]))\n",
    "assert test_grid[coords[:,0], coords[:,1]] == 63.\n",
    "\n",
    "tile_row = t.tensor(1)\n",
    "tile_col = t.tensor(1)\n",
    "tile_coords = (t.tensor(1),t.tensor(1)) \n",
    "coords = get_grid_coords(grid_dim, tile_dim, tile_row, tile_col, tile_coords)\n",
    "assert t.all(coords == t.tensor([(2,2)]))\n",
    "assert test_grid[coords[:,0], coords[:,1]] == 18.\n",
    "\n",
    "tile_row = t.tensor(1)\n",
    "tile_col = t.tensor(1)\n",
    "tile_coords = (t.tensor(2),t.tensor(1)) \n",
    "coords = get_grid_coords(grid_dim, tile_dim, tile_row, tile_col, tile_coords)\n",
    "assert t.all(coords == t.tensor([(3,2)]))\n",
    "assert test_grid[coords[:,0], coords[:,1]] == 26.\n",
    "\n",
    "tile_row = t.tensor((0, 1))\n",
    "tile_col = t.tensor((0, 1))\n",
    "tile_coords = (t.tensor((0, 2)),t.tensor((0, 1))) \n",
    "coords = get_grid_coords(grid_dim, tile_dim, tile_row, tile_col, tile_coords)\n",
    "assert t.all(coords == t.tensor([(7,7),(3,2)]))\n",
    "assert t.all(test_grid[coords[:,0], coords[:,1]] == t.tensor((63, 26)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo step scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subdomains(grid):\n",
    "    subgrids = split_grids(grid, kernel_width=4, kernel_height=4)\n",
    "    tile_set1 = subgrids[0, [0, 4, 28, 32]].reshape(4,4,4)\n",
    "    tile_rows1 = t.tensor([0,0,2,2])\n",
    "    tile_cols1 = t.tensor([0,2,0,2])\n",
    "    subdomain1 = (tile_set1, tile_rows1, tile_cols1)\n",
    "\n",
    "    tile_set2 = subgrids[0, [2, 6, 30, 34]].reshape(4,4,4)\n",
    "    tile_rows2 = t.tensor([0,0,2,2])\n",
    "    tile_cols2 = t.tensor([1,3,1,3])\n",
    "    subdomain2 = (tile_set2, tile_rows2, tile_cols2)\n",
    "\n",
    "    tile_set3 = subgrids[0, [16, 20, 44, 48]].reshape(4,4,4)\n",
    "    tile_rows3 = t.tensor([1,1,3,3])\n",
    "    tile_cols3 = t.tensor([1,3,1,3])\n",
    "    subdomain3 = (tile_set3, tile_rows3, tile_cols3)\n",
    "\n",
    "    tile_set4 = subgrids[0, [14, 18, 42, 46]].reshape(4,4,4)\n",
    "    tile_rows4 = t.tensor([1,1,3,3])\n",
    "    tile_cols4 = t.tensor([0,2,0,2])\n",
    "    subdomain4 = (tile_set4, tile_rows4, tile_cols4)\n",
    "\n",
    "\n",
    "    checkerboard_batch = (subdomain1, subdomain2, subdomain3, subdomain4)\n",
    "    \n",
    "    return checkerboard_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tile_batch(grid, idx):\n",
    "    subgrids = split_grids(grid, kernel_width=4, kernel_height=4)\n",
    "    if idx == 0:\n",
    "        tile_set = subgrids[0, [0, 4, 28, 32]].reshape(4,4,4)\n",
    "        tile_rows = t.tensor([0,0,2,2])\n",
    "        tile_cols = t.tensor([0,2,0,2])\n",
    "        subdomain = (tile_set, tile_rows, tile_cols)\n",
    "        return subdomain\n",
    "\n",
    "    elif idx == 1:\n",
    "        tile_set = subgrids[0, [2, 6, 30, 34]].reshape(4,4,4)\n",
    "        tile_rows = t.tensor([0,0,2,2])\n",
    "        tile_cols = t.tensor([1,3,1,3])\n",
    "        subdomain = (tile_set, tile_rows, tile_cols)\n",
    "        return subdomain\n",
    "\n",
    "    elif idx == 2:\n",
    "        tile_set = subgrids[0, [16, 20, 44, 48]].reshape(4,4,4)\n",
    "        tile_rows = t.tensor([1,1,3,3])\n",
    "        tile_cols = t.tensor([1,3,1,3])\n",
    "        subdomain = (tile_set, tile_rows, tile_cols)\n",
    "        return subdomain\n",
    "\n",
    "    else:\n",
    "        tile_set = subgrids[0, [14, 18, 42, 46]].reshape(4,4,4)\n",
    "        tile_rows = t.tensor([1,1,3,3])\n",
    "        tile_cols = t.tensor([0,2,0,2])\n",
    "        subdomain = (tile_set, tile_rows, tile_cols)\n",
    "        return subdomain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def MCS(batch, target_vol, temperature):\n",
    "    _, batch_height, batch_width = batch.shape\n",
    "    vol_kernel = t.tensor([[[\n",
    "        [0., 0., 0.],\n",
    "        [0., 1., 0.],\n",
    "        [0., 0., 0.]\n",
    "    ]]])\n",
    "    \n",
    "    #checkerboard_batch = get_subdomains(batch)\n",
    "    # iterate over the sets of spaced out sub-grids\n",
    "    steps = []\n",
    "    for domain_idx in range(4):\n",
    "        padded_batch = periodic_padding(batch).unsqueeze(1)\n",
    "        cur_vol = t.sum(t.nn.functional.conv2d(padded_batch, vol_kernel))\n",
    "        #print(f\"current volume: {cur_vol}\")\n",
    "        subdomains = get_tile_batch(batch, domain_idx)\n",
    "        subgrids, tile_rows, tile_cols = subdomains\n",
    "        tiles_per_batch, subgrid_height, subgrid_width = subgrids.shape\n",
    "        src_x = t.randint_like(t.zeros(tiles_per_batch,), low=1, high=int(subgrid_width-2+1))\n",
    "        src_x = src_x.type(t.long)\n",
    "        src_y = t.randint_like(src_x, low=1, high=int(subgrid_height-2+1))\n",
    "        # For each random sample in src, we sample a random value from [-1, 0, 1]\n",
    "        # and add it on to the src_idx\n",
    "        step_sizes = t.tensor(random.choices([\n",
    "            (1, 0),\n",
    "            (1, 1),\n",
    "            (0, 1),\n",
    "            (-1, 1),\n",
    "            (-1, 0),\n",
    "            (-1, -1),\n",
    "            (0, -1),\n",
    "            (1, -1)\n",
    "        ], k=tiles_per_batch))\n",
    "        tgt_x = src_x + step_sizes[:, 1]\n",
    "        tgt_y = src_y + step_sizes[:, 0]\n",
    "        \n",
    "        update_probability = p_update(\n",
    "            subgrids,\n",
    "            cur_vol,\n",
    "            target_vol,\n",
    "            temperature,\n",
    "            (src_x, src_y),\n",
    "            (tgt_x, tgt_y)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        #print(f\"p_update: {update_probability}\")\n",
    "        \n",
    "        residuals = t.rand_like(update_probability)\n",
    "        \n",
    "        #mask = update_probabilities > residuals\n",
    "        #update_x_tgt = tgt_x[mask]\n",
    "        #update_y_tgt = tgt_y[mask]\n",
    "        #update_x_src = src_x[mask]\n",
    "        #update_y_src = src_y[mask]\n",
    "        \n",
    "        #batch_coords_src = get_grid_coords(\n",
    "        #    grid_dim=(batch_height, batch_width),\n",
    "        #    tile_dim=(subgrid_height-2, subgrid_width-2),\n",
    "        #    tile_row=tile_rows[mask],\n",
    "        #    tile_col=tile_cols[mask],\n",
    "        #    tile_coords=(update_y_src, update_x_src)\n",
    "        #)\n",
    "        \n",
    "        #batch_coords_tgt = get_grid_coords(\n",
    "        #    grid_dim=(batch_height, batch_width),\n",
    "        #    tile_dim=(subgrid_height-2, subgrid_width-2),\n",
    "        #    tile_row=tile_rows[mask],\n",
    "        #    tile_col=tile_cols[mask],\n",
    "        #    tile_coords=(update_y_tgt, update_x_tgt)\n",
    "        #)\n",
    "        \n",
    "        if update_probability > residuals:\n",
    "        \n",
    "            batch_coords_src = get_grid_coords(\n",
    "                grid_dim=(batch_height, batch_width),\n",
    "                tile_dim=(subgrid_height-2, subgrid_width-2),\n",
    "                tile_row=tile_rows,\n",
    "                tile_col=tile_cols,\n",
    "                tile_coords=(src_y, src_x)\n",
    "            )\n",
    "            \n",
    "            batch_coords_tgt = get_grid_coords(\n",
    "                grid_dim=(batch_height, batch_width),\n",
    "                tile_dim=(subgrid_height-2, subgrid_width-2),\n",
    "                tile_row=tile_rows,\n",
    "                tile_col=tile_cols,\n",
    "                tile_coords=(tgt_y, tgt_x)\n",
    "            )\n",
    "            \n",
    "            \n",
    "            #print(f\"src: X: {src_x}, Y: {src_y}, V: {subgrids[range(tiles_per_batch), src_x, src_y]}\")\n",
    "            #print(f\"tgt: X: {tgt_x}, Y: {tgt_y}, V: {subgrids[range(tiles_per_batch), tgt_x, tgt_y]}\")\n",
    "            #print(mask)\n",
    "            #subdomains[t.where(mask), update_x_tgt, update_y_tgt] *= 0\n",
    "            #subdomains[t.where(mask), update_x_tgt, update_y_tgt] += subdomains[t.where(mask), update_x_src, update_y_src]\n",
    "            batch[0, batch_coords_tgt[:,0], batch_coords_tgt[:,1]] *= 0\n",
    "            batch[0, batch_coords_tgt[:,0], batch_coords_tgt[:,1]] += batch[0, batch_coords_src[:,0], batch_coords_src[:,1]]\n",
    "    \n",
    "            steps.append(batch.detach().squeeze().clone().numpy())\n",
    "    return batch, steps\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = t.zeros(1,8,8)\n",
    "test[0,3,3] = 1\n",
    "target_vol = 1.\n",
    "temperature = 27.\n",
    "\n",
    "\n",
    "test, steps = MCS(test, target_vol, temperature)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 217.77it/s]\n"
     ]
    }
   ],
   "source": [
    "test = t.zeros(1,8,8)\n",
    "test[0,3,3] = 1\n",
    "target_vol = 1.\n",
    "temperature = 27.\n",
    "\n",
    "states = [test.detach().clone().squeeze().numpy()]\n",
    "for i in tqdm(range(1000)):\n",
    "    #print(f\"--------------MCS: {i+1} --------------\")\n",
    "    test, steps = MCS(test, target_vol, temperature)\n",
    "    states += steps\n",
    "    if t.sum(test) == 0 or t.sum(test) > 2:\n",
    "        print(test)\n",
    "        break\n",
    "\n",
    "imgs = [Image.fromarray((1-state)*255) for state in states]\n",
    "imgs[0].save(\"t_27.gif\", save_all=True, append_images=imgs[1:], duration=10, loop=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:04<00:00, 214.82it/s]\n"
     ]
    }
   ],
   "source": [
    "test = t.zeros(1,8,8)\n",
    "test[0,3,3] = 1\n",
    "target_vol = 1.\n",
    "temperature = 13.\n",
    "\n",
    "states = [test.detach().clone().squeeze().numpy()]\n",
    "for i in tqdm(range(1000)):\n",
    "    #print(f\"--------------MCS: {i+1} --------------\")\n",
    "    test, steps = MCS(test, target_vol, temperature)\n",
    "    states += steps\n",
    "    if t.sum(test) == 0 or t.sum(test) > 2:\n",
    "        print(test)\n",
    "        break\n",
    "\n",
    "imgs = [Image.fromarray((1-state)*255) for state in states]\n",
    "imgs[0].save(\"t_13.gif\", save_all=True, append_images=imgs[1:], duration=10, loop=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 387.02it/s]\n"
     ]
    }
   ],
   "source": [
    "test = t.zeros(1,8,8)\n",
    "test[0,3,3] = 1\n",
    "target_vol = 1.\n",
    "temperature = 0.\n",
    "\n",
    "states = [test.detach().clone().squeeze().numpy()]\n",
    "for i in tqdm(range(1000)):\n",
    "    #print(f\"--------------MCS: {i+1} --------------\")\n",
    "    test, steps = MCS(test, target_vol, temperature)\n",
    "    states += steps\n",
    "    if t.sum(test) == 0 or t.sum(test) > 2:\n",
    "        print(test)\n",
    "        break\n",
    "\n",
    "imgs = [Image.fromarray((1-state)*255) for state in states]\n",
    "imgs[0].save(\"t_0.gif\", save_all=True, append_images=imgs[1:], duration=10, loop=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
