{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t \n",
    "from torch.distributions import uniform\n",
    "from typing import List, Callable\n",
    "from ste_func import STEFunction\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from reaction import rho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p1_(batch: t.Tensor, N: int, gamma: float, k1: float) -> t.Tensor:\n",
    "    n = batch[:,0]\n",
    "    # k1_bar = k1 / ((N - 1) * (N - 2))\n",
    "    return gamma * (k1 / ((N-1)*(N-2))) * n * (n - 1) * (N - n)\n",
    "\n",
    "\n",
    "def p2_(batch: t.Tensor, N: int, gamma: float, k1_star: float) -> t.Tensor:\n",
    "    n = batch[:,0]\n",
    "    # k1_star_bar = k1_star / ((N - 1) * (N - 2))\n",
    "    return gamma * (k1_star / ((N-1) * (N-2))) * n * (N - n) * (N - 1 - n)\n",
    "\n",
    "\n",
    "def p3_(cells: t.Tensor, N: int, gamma: float, k2: float) -> t.Tensor:\n",
    "    n = cells[:,0]\n",
    "    m = cells[:,1]\n",
    "    # k2_bar = k2 / N\n",
    "    return gamma * (k2 / N) * (N - n) * m\n",
    "\n",
    "\n",
    "def p4_(cells: t.Tensor, N: int, gamma: float, k2_star: float) -> t.Tensor:\n",
    "    n = cells[:,0]\n",
    "    m = cells[:,1]\n",
    "    # k2_star_bar = k2_star / N\n",
    "    return gamma * (k2_star / N) * n * (N - m)\n",
    "\n",
    "\n",
    "def p5_(cells: t.Tensor, N: int, gamma: float, k3: float) -> t.Tensor:\n",
    "    n = cells[:,0]\n",
    "    m = cells[:,1]\n",
    "    # k3_bar = k3 / N\n",
    "    return gamma * (k3 / N) * (N - n) * (N - m)\n",
    "\n",
    "\n",
    "def p6_(cells: t.Tensor, N: int, gamma: float, k3_star: float) -> t.Tensor:\n",
    "    n = cells[:,0]\n",
    "    m = cells[:,1]\n",
    "    # k3_star_bar = k3_star / N\n",
    "    return gamma * (k3_star / N) * n * m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rho_STE(\n",
    "    batch: t.Tensor,\n",
    "    N: int,\n",
    "    gamma: t.Tensor,\n",
    "    k1: t.Tensor,\n",
    "    k1_bar: t.Tensor,\n",
    "    k2: t.Tensor,\n",
    "    k2_bar: t.Tensor,\n",
    "    k3: t.Tensor,\n",
    "    k3_bar: t.Tensor,\n",
    "    num_reaction_channels: int,\n",
    "):\n",
    "    batch_size, grids_per_el, height, width = batch.shape\n",
    "    # for each cell on the lattice, choose a reaction channel\n",
    "    channels = t.randint(high=num_reaction_channels,\n",
    "                         size=(batch_size, height, width))\n",
    "    if batch.is_cuda:\n",
    "        channels = channels.cuda()\n",
    "    \n",
    "    # handle reaction 1\n",
    "    p_r1 = p1_(batch, N, gamma, k1)\n",
    "    p_r1_expand = t.stack((p_r1, t.zeros(batch_size, height, width)), dim=1)\n",
    "    chnl_msk = t.stack((channels == 0, t.zeros(batch_size, height, width)),dim=1)\n",
    "    thresholds = uniform.Uniform(0, 1).sample((batch_size, 2, height, width))\n",
    "    #batch += STEFunction.apply(p_r1_expand - thresholds) * chnl_msk\n",
    "    p_r1_res = STEFunction.apply(p_r1_expand - thresholds) * chnl_msk\n",
    "\n",
    "    # handle reaction 2\n",
    "    p_r2 = p2_(batch, N, gamma, k1_bar)\n",
    "    p_r2_expand = t.stack((p_r2, t.zeros(batch_size, height, width)), dim=1)\n",
    "    chnl_msk = t.stack((channels == 1, t.zeros(batch_size, height, width)), dim=1)\n",
    "    thresholds = uniform.Uniform(0, 1).sample((batch_size, 2, height, width))\n",
    "    #batch -= STEFunction.apply(p_r2_expand - thresholds) * chnl_msk\n",
    "    p_r2_res = STEFunction.apply(p_r2_expand - thresholds) * chnl_msk\n",
    "\n",
    "    # handle reaction 3\n",
    "    p_r3 = p3_(batch, N, gamma, k2)\n",
    "    p_r3_expand = t.stack((p_r3, t.zeros(batch_size, height, width)), dim=1)\n",
    "    chnl_msk = t.stack((channels == 2, t.zeros(batch_size, height, width)), dim=1)\n",
    "    thresholds = uniform.Uniform(0, 1).sample((batch_size, 2, height, width))\n",
    "    #batch += STEFunction.apply(p_r3_expand - thresholds) * chnl_msk\n",
    "    p_r3_res = STEFunction.apply(p_r3_expand - thresholds) * chnl_msk\n",
    "\n",
    "    # handle reaction 4\n",
    "    p_r4 = p4_(batch, N, gamma, k2_bar)\n",
    "    p_r4_expand = t.stack((p_r4, t.zeros(batch_size, height, width)), dim=1)\n",
    "    chnl_msk = t.stack((channels == 3, t.zeros(batch_size, height, width)), dim=1)\n",
    "    thresholds = uniform.Uniform(0, 1).sample((batch_size, 2, height, width))\n",
    "    #batch -= STEFunction.apply(p_r4_expand - thresholds) * chnl_msk\n",
    "    p_r4_res = STEFunction.apply(p_r4_expand - thresholds) * chnl_msk\n",
    "\n",
    "    # handle reaction 5\n",
    "    p_r5 = p5_(batch, N, gamma, k3)\n",
    "    p_r5_expand = t.stack((t.zeros(batch_size, height, width), p_r5), dim=1)\n",
    "    chnl_msk = t.stack((t.zeros(batch_size, height, width), channels == 4), dim=1)\n",
    "    thresholds = uniform.Uniform(0, 1).sample((batch_size, 2, height, width))\n",
    "    #batch += STEFunction.apply(p_r5_expand - thresholds) * chnl_msk\n",
    "    p_r5_res = STEFunction.apply(p_r5_expand - thresholds) * chnl_msk\n",
    "\n",
    "    # handle reaction 6\n",
    "    p_r6 = p6_(batch, N, gamma, k3_bar)\n",
    "    p_r6_expand = t.stack((t.zeros(batch_size, height, width), p_r6), dim=1)\n",
    "    chnl_msk = t.stack((t.zeros(batch_size, height, width), channels == 5), dim=1)\n",
    "    #batch -= STEFunction.apply(p_r6_expand - thresholds) * chnl_msk\n",
    "    p_r6_res = STEFunction.apply(p_r6_expand - thresholds) * chnl_msk\n",
    "            \n",
    "    return batch + p_r1_res - p_r2_res + p_r3_res - p_r4_res + p_r5_res - p_r6_res\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from reaction import p1, p2, p3, p4, p5, p6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chop_and_shuffle_data(sequence, shuffle=True):\n",
    "    \"\"\"\n",
    "    Chop the training data into a set of state transitions and shuffle the resulting set.\n",
    "\n",
    "    sequences (np.ndarray): matrix of shape (n_sequences, steps_per_seq, grid_height, grid_width)\n",
    "    \"\"\"\n",
    "    steps_per_seq, _, grid_height, grid_width = sequence.shape\n",
    "    # each transition consists of 2 states\n",
    "    indexer = np.arange(2)[None, :] + np.arange(steps_per_seq - 1)[:, None]\n",
    "    chopped_set = np.zeros(\n",
    "        [(steps_per_seq - 1), 2, 2, grid_height, grid_width]\n",
    "    )\n",
    "    chopped_set = sequence.detach().numpy()[indexer]\n",
    "    if shuffle:\n",
    "        np.random.shuffle(chopped_set)\n",
    "    return t.tensor(chopped_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(13050.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = t.zeros((2,15,15))\n",
    "grid[:] = 50\n",
    "grid[0,12:17] = 90\n",
    "N = 100 \n",
    "gamma = 0.005 \n",
    "rate_coefficients = t.tensor([0.98,0.98,0.1,0.1,0.2,0.2])\n",
    "probability_funcs = [p1,p2,p3,p4,p5,p6]\n",
    "num_steps = 1_000\n",
    "t.sum(grid[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]/root/anaconda3/lib/python3.9/site-packages/torch/distributions/distribution.py:167: UserWarning: sample_n will be deprecated. Use .sample((n,)) instead\n",
      "  warnings.warn('sample_n will be deprecated. Use .sample((n,)) instead', UserWarning)\n",
      "100%|██████████| 1000/1000 [00:03<00:00, 295.94it/s]\n"
     ]
    }
   ],
   "source": [
    "grid = grid.float()\n",
    "sequence = t.zeros((num_steps, *grid.shape))\n",
    "\n",
    "for i in tqdm(range(num_steps)):\n",
    "    sequence[i] = grid.detach().clone()\n",
    "    grid = rho(grid, N, gamma, rate_coefficients, probability_funcs, num_reaction_channels=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = chop_and_shuffle_data(sequence=sequence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(X, Y):\n",
    "    return t.mean(t.sum((X-Y)**2, dim=((1,2,3))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist(X, D1, D2):\n",
    "    mse_D1 = MSE(X, D1)\n",
    "    #print(mse_D1)\n",
    "    mse_D2 = MSE(X, D2)\n",
    "    #print(mse_D2)\n",
    "    return (mse_D1 - mse_D2)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.2445),)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k1 = t.tensor(0.3)\n",
    "k1_bar = t.tensor(0.98)\n",
    "k2 = t.tensor(0.1)\n",
    "k2_bar = t.tensor(0.1)\n",
    "k3 = t.tensor(0.2)\n",
    "k3_bar = t.tensor(0.2)\n",
    "gamma = t.tensor(0.005)\n",
    "X_ = dataset[:,0]\n",
    "X = X_.clone().detach()\n",
    "Y_obs = dataset[:,1]\n",
    "\n",
    "k1.requires_grad_()\n",
    "Y_sim = rho_STE(X, N, gamma, k1, k1_bar, k2, k2_bar, k3, k3_bar, num_reaction_channels=6)\n",
    "dist_val = dist(X_, Y_obs, Y_sim)\n",
    "t.autograd.set_detect_anomaly(True)\n",
    "t.autograd.grad(dist_val, k1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "61a57a4b5406d2de388e2f91097d4e4bcd7d5f4a46f53a795aa28a02eed27fc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
